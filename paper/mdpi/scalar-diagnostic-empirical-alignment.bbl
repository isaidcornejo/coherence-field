\begin{thebibliography}{999}

\bibitem[Fisher(1922)]{Fisher1922}
Fisher, R.A.
\newblock On the Mathematical Foundations of Theoretical Statistics.
\newblock {\em Philosophical Transactions of the Royal Society A} {\bf 1922},
  {\em 222},~309--368.
\newblock {\url{https://doi.org/10.1098/rsta.1922.0009}}.

\bibitem[Rao(1945)]{Rao1945}
Rao, C.R.
\newblock Information and the Accuracy Attainable in the Estimation of
  Statistical Parameters.
\newblock {\em Bulletin of the Calcutta Mathematical Society} {\bf 1945}, {\em
  37},~81--89.

\bibitem[Amari and Nagaoka(2000)]{AmariNagaoka2000}
Amari, S.i.; Nagaoka, H.
\newblock {\em Methods of Information Geometry}; Translations of Mathematical
  Monographs, American Mathematical Society,  2000.
\newblock {\url{https://doi.org/10.1007/978-1-4612-0167-1}}.

\bibitem[Amari(2016)]{Amari2016}
Amari, S.i.
\newblock {\em Information Geometry and Its Applications}; Springer,  2016.
\newblock {\url{https://doi.org/10.1007/978-3-319-56478-4}}.

\bibitem[Amari(1998)]{Amari1998}
Amari, S.i.
\newblock Natural Gradient Works Efficiently in Learning.
\newblock {\em Neural Computation} {\bf 1998}, {\em 10},~251--276.
\newblock {\url{https://doi.org/10.1162/089976698300017746}}.

\bibitem[Martens(2014)]{Martens2014}
Martens, J.
\newblock New Insights and Perspectives on the Natural Gradient Method.
\newblock {\em arXiv:1412.1193} {\bf 2014}.

\bibitem[Brown(1986)]{Brown1986}
Brown, L.D.
\newblock {\em Fundamentals of Statistical Exponential Families}; Institute of
  Mathematical Statistics,  1986.

\bibitem[Wainwright and Jordan(2008)]{WainwrightJordan2008}
Wainwright, M.J.; Jordan, M.I.
\newblock Graphical Models, Exponential Families, and Variational Inference.
\newblock {\em Foundations and Trends in Machine Learning} {\bf 2008}, {\em
  1},~1--305.
\newblock {\url{https://doi.org/10.1561/2200000001}}.

\bibitem[Papyan et~al.(2020)Papyan, Han, and Donoho]{Papyan2019}
Papyan, V.; Han, X.Y.; Donoho, D.L.
\newblock Prevalence of Neural Collapse During the Terminal Phase of Deep
  Learning Training.
\newblock {\em PNAS} {\bf 2020}, {\em 117},~24652--24663.
\newblock {\url{https://doi.org/10.1073/pnas.2010055117}}.

\bibitem[Sagun et~al.(2016)Sagun, Bottou, and LeCun]{Sagun2016}
Sagun, L.; Bottou, L.; LeCun, Y.
\newblock Eigenvalues of the Hessian in Deep Learning: Singularity and Beyond.
\newblock {\em arXiv:1611.07476} {\bf 2016}.

\bibitem[Ghorbani and Krishnan(2018)]{Laurent2018}
Ghorbani, B.; Krishnan, S.
\newblock An Investigation into Neural Net Hessians.
\newblock {\em arXiv:1810.05487} {\bf 2018}.

\bibitem[Nakkiran et~al.(2020)]{Nakkiran2020}
Nakkiran, P.;  et~al.
\newblock Deep Double Descent: Where Bigger Models and More Data Hurt.
\newblock {\em ICLR} {\bf 2020}.

\bibitem[Kotz et~al.(2001)Kotz, Kozubowski, and
  Podgórski]{LaplaceDistribution}
Kotz, S.; Kozubowski, T.; Podgórski, K.
\newblock The Laplace Distribution and Generalizations.
\newblock {\em Springer Series in Statistics} {\bf 2001}.
\newblock {\url{https://doi.org/10.1007/b97636}}.

\bibitem[McLachlan and Peel(2000)]{McLachlanPeel2000}
McLachlan, G.; Peel, D.
\newblock {\em Finite Mixture Models}; Wiley,  2000.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and Haffner]{LeCun1998}
LeCun, Y.; Bottou, L.; Bengio, Y.; Haffner, P.
\newblock Gradient-Based Learning Applied to Document Recognition.
\newblock {\em Proceedings of the IEEE} {\bf 1998}, {\em 86},~2278--2324.
\newblock {\url{https://doi.org/10.1109/5.726791}}.

\end{thebibliography}
